#!/bin/bash -e

# Generate SNB dataset.

function print_help () {
    echo "Usage: $0 [OPTION]"
    echo "Optional arguments:"
    echo -e "  -h|--help -> Prints help."
    echo -e "  --scale-factor Positive_Integer -> Defines the dataset size."
}

script_dir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
base_dir="${script_dir}/../../.."
neo4j_dir="${base_dir}/libs/neo4j"
build_dir="${base_dir}/build"

# Add Maven to PATH
export PATH=$PATH:${script_dir}/maven/bin

# Read the arguments.
scale_factor=1
skip_generating=false
while [[ $# -gt 0 ]]
do
    case $1 in
        -h|--help)
        print_help
        exit 1
        ;;
        --scale-factor)
        scale_factor=$2
        shift
        ;;
        *)
        # unknown option
        ;;
    esac
    shift # past argument or value
done

# Prepare the folder structure.
dataset_dir="${script_dir}/datasets/scale_${scale_factor}"
if [ -d ${dataset_dir} ]; then
    rm -rf ${dataset_dir}
fi
mkdir -p ${dataset_dir}

# Define scale factor.
echo "Using scale_factor" $scale_factor
cat > ${script_dir}/ldbc_snb_datagen/params.ini <<EOF
ldbc.snb.datagen.generator.scaleFactor:snb.interactive.${scale_factor}
ldbc.snb.datagen.serializer.personSerializer:ldbc.snb.datagen.serializer.snb.interactive.CSVPersonSerializer
ldbc.snb.datagen.serializer.invariantSerializer:ldbc.snb.datagen.serializer.snb.interactive.CSVInvariantSerializer
ldbc.snb.datagen.serializer.personActivitySerializer:ldbc.snb.datagen.serializer.snb.interactive.CSVPersonActivitySerializer
EOF

# Find installed Java binary.
if [[ -d "/usr/lib/jvm/default-java/jre" ]]; then
    export JAVA_HOME=/usr/lib/jvm/default-java/jre
elif [[ -d "/usr/lib/jvm/default-runtime/" ]]; then
    export JAVA_HOME=/usr/lib/jvm/default-runtime/
else
    echo "Unable to find JRE under /usr/lib/jvm"
    exit 1
fi
echo "Using JAVA_HOME" $JAVA_HOME

# Remove old generated dataset.
rm -rf ${ldbc_snb_datagen_folder}/social_network ${ldbc_snb_datagen_folder}/substitution_parameters

# Generate the dataset.
ldbc_snb_datagen_folder=${script_dir}/ldbc_snb_datagen
cd ${ldbc_snb_datagen_folder}
# Poorly documented hadoop heapsize flag (unit is 'm'), see: hadoop/libexec/hadoop-config.sh
# https://stackoverflow.com/questions/15609909/error-java-heap-space
export HADOOP_HEAPSIZE=8192
HADOOP_HOME=${script_dir}/hadoop LDBC_SNB_DATAGEN_HOME=${ldbc_snb_datagen_folder} ./run.sh

# Copy generated dataset.
cp -r ${ldbc_snb_datagen_folder}/social_network ${dataset_dir}/
cp -r ${ldbc_snb_datagen_folder}/substitution_parameters ${dataset_dir}/

# Transform the dataset into Neo4j CSV format.
mkdir -p ${dataset_dir}/csv
cd ${script_dir}/ldbc-snb-impls/snb-interactive-neo4j
mvn exec:java \
    -Dexec.mainClass="net.ellitron.ldbcsnbimpls.interactive.neo4j.util.DataFormatConverter" \
    -Dexec.args="${ldbc_snb_datagen_folder}/social_network ${dataset_dir}/csv"

csv_dataset="
--nodes ${dataset_dir}/csv/comment_0_0.csv \
--nodes ${dataset_dir}/csv/forum_0_0.csv \
--nodes ${dataset_dir}/csv/organisation_0_0.csv \
--nodes ${dataset_dir}/csv/person_0_0.csv \
--nodes ${dataset_dir}/csv/place_0_0.csv \
--nodes ${dataset_dir}/csv/post_0_0.csv \
--nodes ${dataset_dir}/csv/tag_0_0.csv \
--nodes ${dataset_dir}/csv/tagclass_0_0.csv \
--relationships ${dataset_dir}/csv/comment_hasCreator_person_0_0.csv \
--relationships ${dataset_dir}/csv/comment_hasTag_tag_0_0.csv \
--relationships ${dataset_dir}/csv/comment_isLocatedIn_place_0_0.csv \
--relationships ${dataset_dir}/csv/comment_replyOf_comment_0_0.csv \
--relationships ${dataset_dir}/csv/comment_replyOf_post_0_0.csv \
--relationships ${dataset_dir}/csv/forum_containerOf_post_0_0.csv \
--relationships ${dataset_dir}/csv/forum_hasMember_person_0_0.csv \
--relationships ${dataset_dir}/csv/forum_hasModerator_person_0_0.csv \
--relationships ${dataset_dir}/csv/forum_hasTag_tag_0_0.csv \
--relationships ${dataset_dir}/csv/organisation_isLocatedIn_place_0_0.csv \
--relationships ${dataset_dir}/csv/person_hasInterest_tag_0_0.csv \
--relationships ${dataset_dir}/csv/person_isLocatedIn_place_0_0.csv \
--relationships ${dataset_dir}/csv/person_knows_person_0_0.csv \
--relationships ${dataset_dir}/csv/person_likes_comment_0_0.csv \
--relationships ${dataset_dir}/csv/person_likes_post_0_0.csv \
--relationships ${dataset_dir}/csv/person_studyAt_organisation_0_0.csv \
--relationships ${dataset_dir}/csv/person_workAt_organisation_0_0.csv \
--relationships ${dataset_dir}/csv/place_isPartOf_place_0_0.csv \
--relationships ${dataset_dir}/csv/post_hasCreator_person_0_0.csv \
--relationships ${dataset_dir}/csv/post_hasTag_tag_0_0.csv \
--relationships ${dataset_dir}/csv/post_isLocatedIn_place_0_0.csv \
--relationships ${dataset_dir}/csv/tag_hasType_tagclass_0_0.csv \
--relationships ${dataset_dir}/csv/tagclass_isSubclassOf_tagclass_0_0.csv"

# Convert to neo4j internal format.
neo4j_database_dir=${dataset_dir}/neo4j/databases
mkdir -p ${neo4j_database_dir}
cd ${neo4j_database_dir}
echo "Converting CSV dataset to '${neo4j_database_dir}/graph.db'"
${neo4j_dir}/bin/neo4j-import --into graph.db ${csv_dataset} --delimiter "|" --array-delimiter ";"

# Convert to memgraph internal format using LOAD CSV and CREATE SNAPSHOT
memgraph_snapshot_dir=${dataset_dir}/memgraph/snapshots
mkdir -p ${memgraph_snapshot_dir}
cd ${memgraph_snapshot_dir}

echo "Creating Memgraph snapshot using LOAD CSV and CREATE SNAPSHOT"

# Create a temporary Memgraph instance for import
temp_memgraph_dir=${dataset_dir}/memgraph/temp
mkdir -p ${temp_memgraph_dir}

# Start Memgraph in background for import
memgraph_binary=${base_dir}/build/memgraph
memgraph_pid_file=${temp_memgraph_dir}/memgraph.pid

# Start Memgraph with temporary data directory
${memgraph_binary} \
    --data-directory ${temp_memgraph_dir} \
    --data-recovery-on-startup false \
    --storage-snapshot-interval-sec 0 \
    --storage-wal-enabled false \
    --storage-snapshot-on-exit false \
    --bolt-port 7688 \
    --log-level TRACE \
    --also-log-to-stderr &
echo $! > ${memgraph_pid_file}

# Wait for Memgraph to start
sleep 5

# Use the separate import script
import_script=${script_dir}/import_ldbc.cypherl

# Copy CSV files to a location accessible by Memgraph
csv_copy_dir=/tmp/ldbc_csv
mkdir -p ${csv_copy_dir}
cp ${dataset_dir}/csv/*.csv ${csv_copy_dir}/

# Import data using mgconsole
echo "Importing data into Memgraph..."
mgconsole_binary=${base_dir}/build/mgconsole
${mgconsole_binary} --host 127.0.0.1 --port 7688 < ${import_script}

# Stop Memgraph
if [ -f ${memgraph_pid_file} ]; then
    kill $(cat ${memgraph_pid_file})
    rm ${memgraph_pid_file}
fi

# Copy the created snapshot to the final location
if [ -d ${temp_memgraph_dir}/snapshots ]; then
    cp -r ${temp_memgraph_dir}/snapshots/* ${memgraph_snapshot_dir}/
    echo "Memgraph snapshot created at '${memgraph_snapshot_dir}'"
else
    echo "Warning: No snapshot found in ${temp_memgraph_dir}/snapshots"
fi

# Clean up temporary files
rm -rf ${temp_memgraph_dir}
rm -rf ${csv_copy_dir}

echo "Done!"
